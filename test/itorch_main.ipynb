{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local torch = require 'torch'\n",
    "require 'hdf5'\n",
    "require 'nn'\n",
    "require 'cunn';\n",
    "require 'cutorch';\n",
    "-- require 'cudnn';\n",
    "require 'paths'\n",
    "require 'xlua'    -- xlua provides useful tools, like progress bars\n",
    "require 'optim'   -- an optimization package, for online and batch methods\n",
    "require 'image'\n",
    "color = require 'trepl.colorize'\n",
    "\n",
    "base_path = '/media/wei/DATA/datasets/vlm/'\n",
    "model_path = '/home/wei/Dropbox/research/gesture & sl & action/my_hand_detector/models/'\n",
    "\n",
    "dataset_size = 'tiny'\n",
    "\n",
    "img_size = {}\n",
    "img_size['H'] = 58\n",
    "img_size['W'] = 58\n",
    "\n",
    "----test nn:\n",
    "--m = nn.SpatialConvolution(1,3,2,2) -- learn 3 2x2 kernels\n",
    "--print(m.weight) -- initially, the weights are randomly initialized\n",
    "\n",
    "---- test cuda:\n",
    "--a = torch.Tensor(5,3) -- construct a 5x3 matrix, uninitialized\n",
    "--b = torch.rand(3,4)\n",
    "--c = torch.Tensor(5,4)\n",
    "--c:mm(a,b) -- store the result of a*b in c\n",
    "--a = a:cuda()\n",
    "--b = b:cuda()\n",
    "--c = c:cuda()\n",
    "--c:mm(a,b) -- done on GPU\n",
    "\n",
    "---- test with table\n",
    "--classes = {key1='Hand', key2='Non-hand'}\n",
    "--print(classes.key1)\n",
    "--print(classes.key2)\n",
    "\n",
    "classes = {}\n",
    "classes[1] = 'Non-hand'\n",
    "classes[2] = 'Hand'\n",
    "itorch.image({image.lena(), image.lena(), image.lena()})\n",
    "print('Classes: 1-' .. classes[1] .. ' 2-' .. classes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "--[[ Test on original hdf5 dataset:\n",
    "--loading hdf5 data of training samples\n",
    "train_file = hdf5.open(base_path .. 'subgestures/ASL_hand_train_tiny.hdf5', 'r')\n",
    "X_train = train_file:read('X_train'):all()\n",
    "y_train = train_file:read('y_train'):all()\n",
    "train_file:close()\n",
    "--loading hdf5 data of test examples\n",
    "test_file = hdf5.open(base_path .. 'subgestures/ASL_hand_test.hdf5', 'r')\n",
    "X_test = test_file:read('X_test'):all()\n",
    "y_test = test_file:read('y_test'):all()\n",
    "test_file:close()\n",
    "\n",
    "N_train = (#X_train)[1]\n",
    "N_test = (#X_test)[1]\n",
    "print('Number of training samples:' .. tostring(N_train))\n",
    "print('Number of test samples:' .. tostring(N_test))\n",
    "---- let's display an image first: (only works with qlua or itorch)\n",
    "itorch.image(X_train[100]) -- display the 100-th image in dataset\n",
    "print(classes[y_train[100]+1])\n",
    "]]\n",
    "\n",
    "trainset = torch.load(base_path .. 'subgestures/' .. 'ASL_torch_hand_train_' .. dataset_size .. '.t7')\n",
    "print('Number of training samples:' .. trainset.data:size(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "---- let's display an image first: (only works with qlua or itorch)\n",
    "itorch.image(trainset.data[1])\n",
    "print(classes[trainset.label[1][1]])\n",
    "itorch.image(trainset.data[25000])\n",
    "print(classes[trainset.label[25000][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset.data = trainset.data:float() -- convert the data from a ByteTensor to a FloatTensor.\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "mean = {} -- store the mean, to normalize the test set in the future\n",
    "stdv  = {} -- store the standard-deviation for the future\n",
    "for i=1,3 do -- over each image channel\n",
    "    mean[i] = trainset.data[{ {}, {i}, {}, {}  }]:mean() -- mean estimation\n",
    "    print('Channel ' .. i .. ', Mean: ' .. mean[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction\n",
    "    \n",
    "    stdv[i] = trainset.data[{ {}, {i}, {}, {}  }]:std() -- std estimation\n",
    "    print('Channel ' .. i .. ', Standard Deviation: ' .. stdv[i])\n",
    "    trainset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--[[ A simple Lenet and Stochastic gradient trainer\n",
    "model:add(nn.SpatialConvolution(3, 6, 5, 5, 1, 1, 2, 2)) \n",
    "model:add(nn.ReLU())                \n",
    "model:add(nn.SpatialMaxPooling(2,2,2,2))    \n",
    "model:add(nn.SpatialConvolution(6, 16, 5, 5, 1, 1, 2, 2))\n",
    "model:add(nn.ReLU())                      \n",
    "model:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "model:add(nn.View(16*14*14))                   \n",
    "model:add(nn.Linear(16*14*14, 120))            \n",
    "model:add(nn.ReLU())                     \n",
    "model:add(nn.Linear(120, 84))\n",
    "model:add(nn.ReLU())                     \n",
    "model:add(nn.Linear(84, 2))              \n",
    "model:add(nn.LogSoftMax())              \n",
    "\n",
    "print('Lemodel\\n' .. model:__tostring());\n",
    "\n",
    "criterion = nn.ClassNLLCriterion()\n",
    "\n",
    "criterion = criterion:cuda()\n",
    "trainset.data = trainset.data:cuda()\n",
    "trainset.label = trainset.label:cuda()\n",
    "\n",
    "trainer = nn.StochasticGradient(model, criterion)\n",
    "trainer.learningRate = 0.01\n",
    "trainer.learningRateDecay = 0.95\n",
    "trainer.maxIteration = 25 \n",
    "\n",
    "trainer:train(trainset)\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opt = {}\n",
    "opt['save'] = 'Logs'\n",
    "opt['batchSize'] = 250\n",
    "opt['learningRateDecay'] = 0.95\n",
    "opt['learningRate'] = 0.003\n",
    "opt['weightDecay'] = 0.0001\n",
    "opt['momentum'] = 0.9\n",
    "opt['model'] = 'customized_model'\n",
    "opt['epoch_step'] = 25\n",
    "opt['max_epoch'] = 300\n",
    "opt['backend'] = 'nn'\n",
    "\n",
    "print(color.blue '==>' ..' configuring model')\n",
    "model = nn.Sequential()\n",
    "-- Copy : add a copy of the input with type casting;\n",
    "model:add(nn.Copy('torch.FloatTensor','torch.CudaTensor'):cuda())\n",
    "model:add(dofile('models/'..opt.model..'.lua'):cuda())\n",
    "-- do not update gradients of Copy layer\n",
    "model:get(1).updateGradInput = function(input) return end \n",
    "\n",
    "if opt.backend == 'cudnn' then\n",
    "   require 'cudnn'\n",
    "   -- convert ReLU to cudnn\n",
    "   cudnn.convert(model:get(2), cudnn) \n",
    "end\n",
    "\n",
    "\n",
    "print('Customized model\\n' .. model:__tostring());\n",
    "--print(model)\n",
    "\n",
    "parameters,gradParameters = model:getParameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion = optim.ConfusionMatrix(2)\n",
    "print('Will save at '..opt.save)\n",
    "paths.mkdir(opt.save)\n",
    "testLogger = optim.Logger(paths.concat(opt.save, 'test.log'))\n",
    "testLogger:setNames{'% mean class accuracy (train set)', '% mean class accuracy (val set)'}\n",
    "testLogger.showPlot = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(color.blue'==>' ..' setting criterion')\n",
    "criterion = nn.CrossEntropyCriterion():cuda()\n",
    "\n",
    "print(color.blue'==>' ..' configuring optimizer')\n",
    "optimState = {\n",
    "  learningRate = opt.learningRate,\n",
    "  weightDecay = opt.weightDecay,\n",
    "  momentum = opt.momentum,\n",
    "  learningRateDecay = opt.learningRateDecay,\n",
    "}\n",
    "print(optimState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function train()\n",
    "  -- sets the mode of the Module (or sub-modules) to train=true\n",
    "  model:training()\n",
    "  epoch = epoch or 1\n",
    "\n",
    "  -- drop learning rate every \"epoch_step\" epochs\n",
    "  if epoch % opt.epoch_step == 0 then optimState.learningRate = optimState.learningRate/2 end\n",
    "  \n",
    "  print(color.blue '==>'..\" online epoch # \" .. epoch .. ' [batchSize = ' .. opt.batchSize .. ']')\n",
    "\n",
    "  local targets = torch.CudaTensor(opt.batchSize)\n",
    "  local indices = torch.randperm(trainset.data:size(1)):long():split(opt.batchSize)\n",
    "  -- remove last element so that all the batches have equal size\n",
    "  indices[#indices] = nil\n",
    "\n",
    "  local tic = torch.tic()\n",
    "  for t,v in ipairs(indices) do\n",
    "    xlua.progress(t, #indices)\n",
    "\n",
    "    local inputs = trainset.data:index(1,v)\n",
    "    targets:copy(trainset.label:index(1,v))\n",
    "\n",
    "    local feval = function(x)\n",
    "      if x ~= parameters then parameters:copy(x) end\n",
    "      gradParameters:zero()\n",
    "      \n",
    "      local outputs = model:forward(inputs)\n",
    "      local f = criterion:forward(outputs, targets)\n",
    "      local df_do = criterion:backward(outputs, targets)\n",
    "      model:backward(inputs, df_do)\n",
    "\n",
    "      confusion:batchAdd(outputs, targets)\n",
    "\n",
    "      return f,gradParameters\n",
    "    end\n",
    "    optim.sgd(feval, parameters, optimState)\n",
    "  end\n",
    "\n",
    "  confusion:updateValids()\n",
    "  print(('Train accuracy: '..color.cyan'%.2f'..' %%\\t time: %.2f s'):format(\n",
    "        confusion.totalValid * 100, torch.toc(tic)))\n",
    "\n",
    "  train_acc = confusion.totalValid * 100\n",
    "\n",
    "  confusion:zero()\n",
    "  epoch = epoch + 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function test()\n",
    "  -- disable flips, dropouts and batch normalization\n",
    "  -- sets the mode of the Module (or sub-modules) to train=false\n",
    "  model:evaluate()\n",
    "\n",
    "  print(color.blue '==>'..\" testing\")\n",
    "    \n",
    "  local bs = 125\n",
    "  for i=1,valset.data:size(1),bs do\n",
    "    local outputs = model:forward(valset.data:narrow(1,i,bs))\n",
    "    confusion:batchAdd(outputs, valset.label:narrow(1,i,bs))\n",
    "  end\n",
    "\n",
    "  confusion:updateValids()\n",
    "  print('Test accuracy:', confusion.totalValid * 100)\n",
    "  \n",
    "  if testLogger then\n",
    "    paths.mkdir(opt.save)\n",
    "    testLogger:add{train_acc, confusion.totalValid * 100}\n",
    "    testLogger:style{'-','-'}\n",
    "    testLogger:plot()\n",
    "\n",
    "    local base64im\n",
    "    do\n",
    "      os.execute(('convert -density 200 %s/test.log.eps %s/test.png'):format(opt.save,opt.save))\n",
    "      os.execute(('openssl base64 -in %s/test.png -out %s/test.base64'):format(opt.save,opt.save))\n",
    "      local f = io.open(opt.save..'/test.base64')\n",
    "      if f then base64im = f:read'*all' end\n",
    "    end\n",
    "\n",
    "    local file = io.open(opt.save..'/report.html','w')\n",
    "    file:write(([[\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <body>\n",
    "    <title>%s - %s</title>\n",
    "    <img src=\"data:image/png;base64,%s\">\n",
    "    <h4>optimState:</h4>\n",
    "    <table>\n",
    "    ]]):format(opt.save,epoch,base64im))\n",
    "    for k,v in pairs(optimState) do\n",
    "      if torch.type(v) == 'number' then\n",
    "        file:write('<tr><td>'..k..'</td><td>'..v..'</td></tr>\\n')\n",
    "      end\n",
    "    end\n",
    "    file:write'</table><pre>\\n'\n",
    "    file:write(tostring(confusion)..'\\n')\n",
    "    file:write(tostring(model)..'\\n')\n",
    "    file:write'</pre></body></html>'\n",
    "    file:close()\n",
    "  end\n",
    "\n",
    "  -- save model every 50 epochs\n",
    "  if epoch % 50 == 0 then\n",
    "    local filename = paths.concat(opt.save, 'model.net')\n",
    "    print('==> saving model to '..filename)\n",
    "    torch.save(filename, model:get(3):clearState())\n",
    "  end\n",
    "\n",
    "  confusion:zero()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "valset = torch.load(base_path .. 'subgestures/' .. 'ASL_torch_hand_val.t7')\n",
    "valset.data = valset.data:float() -- convert the data from a ByteTensor to a FloatTensor.\n",
    "-- print the mean and standard-deviation of example-100\n",
    "sample = valset.data[100]\n",
    "print(sample:mean(), sample:std())\n",
    "print(classes[valset.label[100][1]]) -- tensor element must be accessed by with index [1] in this case\n",
    "itorch.image(valset.data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- normalize val samples\n",
    "for i=1,3 do -- over each image channel\n",
    "    valset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction    \n",
    "    valset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end\n",
    "valset.data = valset.data:cuda() -- or error occurs: (cannot convert 'struct THCudaTensor *' to 'struct THDoubleTensor *')\n",
    "-- valset.label = valset.label:cuda() -- shouldn't be converted into cuda tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i=1,opt.max_epoch do\n",
    "  train()\n",
    "  test()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted = model:forward(valset.data[100])\n",
    "-- the output of the modelwork is Log-Probabilities. To convert them to probabilities, you have to take e^x \n",
    "print(predicted:exp())\n",
    "--To make it clearer, let us tag each probability with it's class-name:\n",
    "for i=1,predicted:size(1) do\n",
    "    print(classes[i] .. ' ' .. predicted[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N_val = valset:size()\n",
    "\n",
    "N_val_pos = 0\n",
    "N_val_neg = 0\n",
    "for i=1,N_val do\n",
    "  if valset.label[i][1] == 1 then\n",
    "    N_val_neg = N_val_neg + 1\n",
    "  else\n",
    "    N_val_pos = N_val_pos + 1\n",
    "  end\n",
    "end\n",
    "print('N_val_neg: ' .. N_val_neg)\n",
    "print('N_val_pos: ' .. N_val_pos)\n",
    "\n",
    "correct = 0\n",
    "for i=1,N_val do\n",
    "    ---- disp progress\n",
    "    --xlua.progress(i, valset:size())\n",
    "    \n",
    "    local groundtruth = valset.label[i][1]\n",
    "    local prediction = model:forward(valset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end\n",
    "print('Accuracy: ', 100*correct/N_val .. '% ')\n",
    "\n",
    "class_performance = {0, 0}\n",
    "for i=1,N_val do\n",
    "    local groundtruth = valset.label[i][1]\n",
    "    local prediction = model:forward(valset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end\n",
    "print('Specificity: ', class_performance[1] / N_val_neg .. '%')\n",
    "print('Sensitivity: ', class_performance[2] / N_val_pos .. '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- space collection\n",
    "for k,v in pairs(trainset) do trainset[k]=nil end\n",
    "for k,v in pairs(valset) do valset[k]=nil end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Evaluate on test set\n",
    "testset = torch.load(base_path .. 'subgestures/' .. 'ASL_torch_hand_test.t7')\n",
    "testset.data = testset.data:float() -- convert the data from a ByteTensor to a FloatTensor.\n",
    "-- normalize test samples\n",
    "for i=1,3 do -- over each image channel\n",
    "    testset.data[{ {}, {i}, {}, {}  }]:add(-mean[i]) -- mean subtraction    \n",
    "    testset.data[{ {}, {i}, {}, {}  }]:div(stdv[i]) -- std scaling\n",
    "end\n",
    "testset.data = testset.data:cuda() -- or error occurs: (cannot convert 'struct THCudaTensor *' to 'struct THDoubleTensor *')\n",
    "N_test = testset:size()\n",
    "N_test_pos = 0\n",
    "N_test_neg = 0\n",
    "for i=1,N_test do\n",
    "  if testset.label[i][1] == 1 then\n",
    "    N_test_neg = N_test_neg + 1\n",
    "  else\n",
    "    N_test_pos = N_test_pos + 1\n",
    "  end\n",
    "end\n",
    "print('N_test_neg: ' .. N_test_neg)\n",
    "print('N_test_pos: ' .. N_test_pos)\n",
    "\n",
    "correct = 0\n",
    "for i=1,N_test do\n",
    "    local groundtruth = testset.label[i][1]\n",
    "    local prediction = model:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        correct = correct + 1\n",
    "    end\n",
    "end\n",
    "print('Accuracy: ', 100*correct/N_test .. '% ')\n",
    "\n",
    "class_performance = {0, 0}\n",
    "for i=1,N_test do\n",
    "    local groundtruth = testset.label[i][1]\n",
    "    local prediction = model:forward(testset.data[i])\n",
    "    local confidences, indices = torch.sort(prediction, true)  -- true means sort in descending order\n",
    "    if groundtruth == indices[1] then\n",
    "        class_performance[groundtruth] = class_performance[groundtruth] + 1\n",
    "    end\n",
    "end\n",
    "print('Specificity: ', class_performance[1] / N_test_neg .. '%')\n",
    "print('Sensitivity: ', class_performance[2] / N_test_pos.. '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = model\n",
    "model_out_path = model_path .. 'ASL_hand_classifier_' .. dataset_size .. '.t7'\n",
    "print('Writing model to file ' .. model_out_path)\n",
    "torch.save(model_out_path, classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
