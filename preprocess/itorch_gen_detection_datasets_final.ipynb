{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local torch = require 'torch'\n",
    "require 'hdf5'\n",
    "require 'image'\n",
    "require 'utilities'\n",
    "require 'Rect' \n",
    "require 'lfs'\n",
    "require 'LuaXML'\n",
    "\n",
    "ASL_BASE_DIR = '/media/wei/DATA/datasets/vlm/snaps/'\n",
    "ASL_ANNO_DIR = '/media/wei/DATA/datasets/vlm/annotations/'\n",
    "\n",
    "img_size = {}\n",
    "img_size['H'] = 58\n",
    "img_size['W'] = 58\n",
    "\n",
    "ground_truth = {}\n",
    "\n",
    "class_names = {}\n",
    "class_names[1] = 'Hand'\n",
    "class_index = {}\n",
    "class_index['Hand'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'csvigo'\n",
    "\n",
    "-- format of csv file:\n",
    "-- image id, image path, hand type, left, top, width, height (left hand), left, top, width, height (right hand),\n",
    "function import_file(dataset_name, name_table)\n",
    "    local m = csvigo.load({path = ASL_ANNO_DIR..'det_GT_'..dataset_name..'.csv', mode = 'large'})\n",
    "    local name = 'Hand'\n",
    "    \n",
    "    print(('%d rows loaded'):format(tostring(#m)))\n",
    "\n",
    "\n",
    "    --format rows: convert coordinates from string to tensor\n",
    "    local ROI = torch.IntTensor(#m, 8):zero()\n",
    "--     print('First row:')\n",
    "--     print(m[1]) -- get element\n",
    "\n",
    "    for i=1, #m do\n",
    "        local cnt = 1\n",
    "        coord = string.sub(m[i][4], 2, -2) -- strip parenthesis\n",
    "        for word in string.gmatch(coord, '([^,]+)') do\n",
    "\n",
    "            ROI[i][cnt] = tonumber(word) -- is +1 necessary?\n",
    "            cnt = cnt + 1\n",
    "        end\n",
    "        \n",
    "        local l_rect = {}\n",
    "        local r_rect = {}\n",
    "        local rois = {}\n",
    "        \n",
    "        local type = tonumber(m[i][3])\n",
    "        if type == 1 then  -- only left hand (rarely used)\n",
    "            l_rect = Rect.new(ROI[i][1], ROI[i][2], ROI[i][1] + ROI[i][3], ROI[i][2] + ROI[i][4])\n",
    "            table.insert(rois, {rect = l_rect, class_index = class_index[name], class_name = name})\n",
    "        elseif type == 2 then -- only right hand\n",
    "            r_rect = Rect.new(ROI[i][5], ROI[i][6], ROI[i][5] + ROI[i][7], ROI[i][6] + ROI[i][8])\n",
    "            table.insert(rois, {rect = r_rect, class_index = class_index[name], class_name = name})\n",
    "        elseif type == 3 then -- both hands\n",
    "            l_rect = Rect.new(ROI[i][1], ROI[i][2], ROI[i][1] + ROI[i][3], ROI[i][2] + ROI[i][4])\n",
    "            r_rect = Rect.new(ROI[i][5], ROI[i][6], ROI[i][5] + ROI[i][7], ROI[i][6] + ROI[i][8])\n",
    "            table.insert(rois, {rect = l_rect, class_index = class_index[name], class_name = name})\n",
    "            table.insert(rois, {rect = r_rect, class_index = class_index[name], class_name = name})\n",
    "        elseif type == 0 then -- no/bad annotation\n",
    "        else\n",
    "            error('Hand type not supported!')\n",
    "        end\n",
    "\n",
    "        local image_path = m[i][2]\n",
    "        table.insert(name_table, image_path)\n",
    "\n",
    "        ground_truth[image_path] = { image_file_name = image_path, rois = rois }\n",
    "    end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function create_ground_truth_file(dataset_name, background_folders, output_fn)\n",
    "    --loading csv files of GT information from training set\n",
    "    local trainset = {}\n",
    "    local testset = {}\n",
    "\n",
    "    import_file('train', trainset)\n",
    "    import_file('test', testset)\n",
    "    \n",
    "    print('Ground truth number: '..tablelength(ground_truth))\n",
    "    print('Training set number: '..#trainset)\n",
    "    print('test set number: '..#testset)\n",
    "    \n",
    "    local file_names = keys(ground_truth)\n",
    "    -- compile list of background images\n",
    "    local background_files = {}\n",
    "\n",
    "    print(string.format('Total images: %d; classes: %d; train_set: %d; validation_set: %d; (Background: %d)', \n",
    "    #file_names, #class_names, #trainset, #testset, #background_files\n",
    "    ))\n",
    "\n",
    "    save_obj(\n",
    "        output_fn,\n",
    "        {\n",
    "          dataset_name = dataset_name,\n",
    "          ground_truth = ground_truth,\n",
    "          training_set = trainset,\n",
    "          validation_set = testset,\n",
    "          class_names = class_names,\n",
    "          class_index = class_index,\n",
    "          background_files = background_files\n",
    "        }\n",
    "    )\n",
    "    print('Done.')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: /media/wei/DATA/datasets/vlm/annotations/det_GT_train.csv\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n",
       "74618 rows loaded\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing file: /media/wei/DATA/datasets/vlm/annotations/det_GT_test.csv\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<csv>\tparsing done\t\n",
       "26827 rows loaded\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Ground truth number: 101445\t\n",
       "Training set number: 74618\t\n",
       "test set number: 26827\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Total images: 101445; classes: 1; train_set: 74618; validation_set: 26827; (Background: 0)\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Done.\t\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local background_folders = {}\n",
    "\n",
    "create_ground_truth_file(\n",
    "  'ASL',\n",
    "  background_folders,\n",
    "  ASL_ANNO_DIR..'ASL_det.t7'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
